{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e65a75-97f1-4e07-af19-5ca78710ebe7",
   "metadata": {},
   "source": "# Scaling Up with the OSPoool: A Wordcount Tutorial for Submitting Many Jobs"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows you how to submit multiple jobs from a single submit file. This enables you to submit your workload without having to create one submit file per task. Use this guide as an introduction to learning how to submit a list of tasks as multiple jobs.\n",
    "\n",
    "## Our list of tasks\n",
    "\n",
    "Imagine you want to analyze how word usage varies from book to book or author to author over a collection of books. This is a common workflow shape, where you have a list of tasks that require different input files or parameters, but the same overall analysis."
   ],
   "id": "749ff82b5450f6d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Getting Ready\n",
    "\n",
    "To get started, let's make sure we are in our `tutorial-wordfreq` directory by printing our working directory:"
   ],
   "id": "f9ce06a89393a33c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cd ~/tutorial-wordfreq",
   "id": "ecf4d5f9aaccdd3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pwd",
   "id": "53927f85ba4e64b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You should see `/home/<username>/tutorial-wordfreq`.\n",
    "\n",
    "If you are running this on the Guest Account, your working directory will be `/home/jovyan/tutorial-wordfreq`.\n",
    "\n",
    "Explore the contents of this directory using the `ls` command or using the file explorer on the left."
   ],
   "id": "db01127cffbb3f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ls -lh",
   "id": "a36634565bc0fbad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This directory should contain a few files and folders, similar to the file explorer on the left.\n",
    "\n",
    "```\n",
    "    ├── tutorial-wordfreq\n",
    "    │   ├── /err\n",
    "    │   ├── /log\n",
    "    │   ├── /out\n",
    "    │   ├── Alice_in_Wonderland.txt\n",
    "    │   ├── Dracula.txt\n",
    "    │   ├── Huckleberry_Finn.txt\n",
    "    │   ├── Pride_and_Prejudice.txt\n",
    "    │   ├── README.md\n",
    "    │   ├── wordcount.py\n",
    "    │   ├── wordcount.sub\n",
    "    │   ├── WordFreq_Tutorial.ipynb\n",
    "```"
   ],
   "id": "a33510410325638"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Submit a single task: analyze one book\n",
    "\n",
    "### Test the command\n",
    "\n",
    "Let's test our analysis to understand the expected behavior. We can analyze the book `Alice_in_Wonderland.txt` by running the `wordcount.py` script:\n"
   ],
   "id": "9defef0857b4e2ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "./wordcount.py Alice_in_Wonderland.txt",
   "id": "62ef11dd570300d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run the `ls` command. You should see a new file, `counts.Alice_in_Wonderland.tsv`, which has the results of this python script. This is the output we want, and the output we expect HTCondor to return to us when our job finishes. For now, remove the output:\n",
   "id": "babbc17a890fc395"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "rm counts.Alice_in_Wonderland.tsv",
   "id": "e2adaa59efcce048"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create a submit file\n",
    "\n",
    "Let's translate this analysis into a form that HTCondor understands, so it can run the analysis for us. We describe this analysis in the form of a submit file.\n",
    "\n",
    "Two key components of our analysis are:\n",
    "\n",
    "1. The executable (`wordcount.py`)\n",
    "2. The input file(s) (`Alice_in_Wonderland.txt`)\n",
    "\n",
    "In HTCondor's submit file syntax, we describe the command we ran with the `executable` and `arguments` options:\n",
    "\n",
    "```plaintext\n",
    "executable = wordcount.py\n",
    "arguments  = Alice_in_Wonderland.txt\n",
    "```\n",
    "\n",
    "The `executable` is the script that we want to run, and the `arguments` is\n",
    "everything else that follows the script when we run it, like the test above.\n",
    "\n",
    "The input file for this job is the `Alice_in_Wonderland.txt`\n",
    "text file. While we provided the name as in the `arguments`, we *also* need\n",
    "to explicitly tell HTCondor to transfer the corresponding file from the Access Point (the machine you're currently on) to the Execution Point (the machine where your job runs).\n",
    "\n",
    "We include the file name in the following submit file option:\n",
    "\n",
    "\n",
    "```plaintext\n",
    "transfer_input_files = Alice_in_Wonderland.txt\n",
    "```\n",
    "\n",
    "There are other submit file options that control other aspects of the job, like\n",
    "where to save error and logging information, and how many resources to request per\n",
    "job. This tutorial has a sample submit file (`wordcount.sub`) with these submit file options filled in for you:\n",
    "\n",
    "```plaintext\n",
    "executable = wordcount.py\n",
    "arguments = Alice_in_Wonderland.txt\n",
    "\n",
    "log = log/job.$(Cluster).$(Process).log\n",
    "error = err/job.$(Cluster).$(Process).err\n",
    "output = out/job.$(Cluster).$(Process).out\n",
    "\n",
    "transfer_input_files = Alice_in_Wonderland.txt\n",
    "\n",
    "request_cpus   = 1\n",
    "request_memory = 1GB\n",
    "request_disk   = 1GB\n",
    "\n",
    "queue 1\n",
    "```\n",
    "\n",
    "Confirm the contents of the submit file by printing it out:"
   ],
   "id": "37aa082907d8a7ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cat wordcount.sub",
   "id": "dfc4b122bfb32353"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are now ready to submit our one-book analysis to the OSPool using HTCondor.",
   "id": "fff2513034ba6ee0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Submit and monitor the job\n",
    "\n",
    "After confirming the submit file, submit the job:"
   ],
   "id": "4e043be9ff710082"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "condor_submit wordcount.sub",
   "id": "29e5f1776780f269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "HTCondor will then print out a unique job ID corresponding to this submission.\n",
    "\n",
    "Check the job's progress using `condor_q`, which will print out a table of your job'(s) status."
   ],
   "id": "99c4d9e292e9948e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "condor_q",
   "id": "e8d8d9ac86a40ca0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can also use the command `condor_watch_q` to monitor the\n",
    "queue in real time (use the keyboard shortcut `Ctrl` + `C` to exit).\n",
    "\n",
    "Once the job finishes, you should see the same `counts.Alice_in_Wonderland.tsv` output when you enter `ls`."
   ],
   "id": "efd202b6d9e6ee61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Submit a list of tasks: analyze multiple books\n",
    "\n",
    "Now suppose you want to analyze multiple books - more than one at a time.\n",
    "You could create a separate submit file for each book, and submit all of the\n",
    "files manually, but you'd have a lot of file lines to modify each time\n",
    "(specifically, the `arguments` and `transfer_input_files` lines from the\n",
    "previous submit file).\n",
    "\n",
    "This would be tedious! HTCondor has options that make it easy to\n",
    "submit many jobs from one submit file.\n",
    "\n",
    "### Make a list\n",
    "\n",
    "HTCondor can loop through a list and submit one job per line of that list - this is perfect for running the *same* analysis for *different* books!\n",
    "\n",
    "First, let's make a list of items that are different for each task we want to run. In this example, the main difference is the books we want to analyze. So, our list should contain the names of these books.\n",
    "\n",
    "We can easily create this list by using an `ls` command and sending the output to a text file that we'll call `book.list`:"
   ],
   "id": "99a15fdbdf80a862"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ls *.txt > book.list",
   "id": "b97749c32ae885c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `book.list` file now contains each of the `.txt` file names in the current directory.",
   "id": "cb07ab735fdcaca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "cat book.list",
   "id": "b6e32ac672314deb",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The output will list the books to analyze and should look something like this:\n",
    "```plaintext\n",
    "Alice_in_Wonderland.txt\n",
    "Dracula.txt\n",
    "Huckleberry_Finn.txt\n",
    "Pride_and_Prejudice.txt\n",
    "```"
   ],
   "id": "cf4f2f2db20a3a98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modify the submit file\n",
    "\n",
    "Next, we will make changes to our submit file so that it submits a job for\n",
    "each book title in our list (seen in the `book.list` file).\n",
    "\n",
    "Create a copy of our existing submit file, which we will use for this job submission.\n"
   ],
   "id": "c51d463a298172d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cp wordcount.sub many-wordcount.sub",
   "id": "be26466a809f19c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We need to tell HTCondor which list to loop over, and what variable we want to assign that value. Open the `many-wordcount.sub` file with a text editor (i.e., `vi`, `nano`) and go to the end.\n",
    "\n",
    "```plaintext\n",
    "queue book from book.list\n",
    "```\n",
    "\n",
    "This statement works like a `for` loop:\n",
    "\n",
    "1. HTcondor looks for the text file, `book.list`\n",
    "1. HTCondor looks at the first line of `book.list` and assigns that value to the variable `book`.\n",
    "1. In the submit file, every occurrence of `$(book)` is replaced by the value assigned to `book`.\n",
    "1. HTCondor submits one job.\n",
    "1. HTCondor then reads the second line of `book.list`, and repeats steps 2-4 until it reaches the end of the list.\n",
    "\n",
    "> The syntax `$(variablename)` represents a submit variable whose value\n",
    "> will be substituted at the time of submission.\n",
    "\n",
    "Now, let's edit the rest of the submit file. Replace the name of the book `Alice_in_Wonderland.txt` in our submit file with the variable `$(book)`.\n",
    "\n",
    "So, the following lines in the submit file should be changed to use the variable `$(book)`:\n",
    "\n",
    "```\n",
    "arguments = $(book)\n",
    "\n",
    "transfer_input_files = $(book)\n",
    "```"
   ],
   "id": "b3043832955a482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Submit and monitor the jobs\n",
    "\n",
    "Let's submit all of our jobs.:\n"
   ],
   "id": "d4febd348df5e775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "condor_submit many-wordcount.sub",
   "id": "fdaeeba3ce5296a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This will now submit four jobs (one for each book on our list). Once all four\n",
    "have finished running, we should see four \"counts\" files, one for each book in the directory.\n",
    "\n",
    "If you don't see all four \"counts\" files, consider investigating the log, error, and output files and see if you can identify what caused that to happen."
   ],
   "id": "d08d0a253fea1ac6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Check Your Job Resource Usage\n",
    "\n",
    "As you scale up your analysis, it's important to monitor the resource usage of your jobs to ensure they are running efficiently. After submitting a small number of test jobs, you can check the log files generated by HTCondor to see how much CPU time, memory, and disk space your jobs are using."
   ],
   "id": "7b47056d58ac42ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cat log/*",
   "id": "b7dbb956ce140c78"
  },
  {
   "cell_type": "markdown",
   "id": "66135640304c9636",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed the Wordcount tutorial, you're ready to build on what you've learned about submitting and managing multiple jobs on the OSPool. Here are some ideas for where to go next:\n",
    "\n",
    "🧮 **Apply These Concepts to Your Own Workflows**\n",
    "* Replace the wordcount script with your own analysis program or data-processing script.\n",
    "* Use a task list (like `book.list`) to handle batches of input files or parameters for your project.\n",
    "* Adjust the submit file to match your resource needs (for example, increase `request_memory` or change the number of CPUs).\n",
    "\n",
    "📦 **Use Containers for Your Software**\n",
    "* Package your Python environment or research tools in an [Apptainer container](https://portal.osg-htc.org/documentation/htc_workloads/using_software/containers-singularity/) so your software runs the same everywhere.\n",
    "* If you’re familiar with Docker, see [Using Docker Containers](https://portal.osg-htc.org/documentation/htc_workloads/using_software/containers-docker/) for how to convert existing Docker images for OSPool use.\n",
    "\n",
    "📁 **Work with Larger or More Complex Data**\n",
    "* Learn how to manage input and output files efficiently across many jobs with the [Data Management Guide](https://portal.osg-htc.org/documentation/htc_workloads/managing_data/overview/).\n",
    "* For large datasets, explore using the [Open Science Data Federation (OSDF)](https://portal.osg-htc.org/documentation/htc_workloads/managing_data/osdf/) for faster, distributed data access.\n",
    "\n",
    "🚀 **Go Further with Parallel Workloads**\n",
    "* Try submitting other types of parameter-sweep or ensemble analyses using the same principles.\n",
    "* Explore tutorials on more advanced job structures, such as [workflow managers](https://portal.osg-htc.org/documentation/htc_workloads/automated_workflows/tutorial-pegasus/) and [domain-specific examples](https://portal.osg-htc.org/documentation/software_examples/bioinformatics/tutorial-fastqc/).\n",
    "\n",
    "🧑‍💻 **Get Help or Collaborate**\n",
    "* Contact [support@osg-htc.org](mailto:support@osg-htc.org) for one-on-one help adapting these ideas to your research.\n",
    "* Join OSPool virtual office hours or training sessions—see the [Get Help](https://portal.osg-htc.org/documentation/support_and_training/support/getting-help-from-RCFs/) page for details.\n",
    "\n",
    "### Software\n",
    "\n",
    "In this tutorial, we used a very simple python script to demonstrate how to submit multiple jobs using HTCondor. However, most research software is more complex and has many dependencies that need to be installed on the machine where the job runs.\n",
    "\n",
    "Our recommendation for most users is to use \"Apptainer\" containers for deploying their software.\n",
    "For instructions on how to build an Apptainer container, see our guide [Using Apptainer/Singularity Containers](https://portal.osg-htc.org/documentation/htc_workloads/using_software/containers-singularity/).\n",
    "If you are familiar with Docker, or want to learn how to use Docker, see our guide [Using Docker Containers](https://portal.osg-htc.org/documentation/htc_workloads/using_software/containers-docker/).\n",
    "\n",
    "This information can also be found in our guide [Using Software on the Open Science Pool](https://portal.osg-htc.org/documentation/htc_workloads/using_software/software-overview/).\n",
    "\n",
    "### Data\n",
    "\n",
    "The ecosystem for moving data to, from, and within the HTC system can be complex, especially if trying to work with large data (> gigabytes).\n",
    "For guides on how data movement works on the HTC system, see our [Data Staging and Transfer to Jobs](https://portal.osg-htc.org/documentation/htc_workloads/managing_data/overview/) guides.\n",
    "\n",
    "### GPUs\n",
    "\n",
    "The OSPool has GPU nodes available for common use. If you would like to learn more about our GPU capacity, please visit our [GPU Guide on the OSPool Documentation Portal](https://portal.osg-htc.org/documentation/htc_workloads/specific_resource/gpu-jobs/).\n",
    "\n",
    "## Getting Help\n",
    "\n",
    "The OSPool Research Computing Facilitators are here to help researchers using the OSPool for their research. We provide a broad swath of research facilitation services, including:\n",
    "\n",
    "* **Web guides**: [OSPool Guides](https://portal.osg-htc.org/documentation/) - instructions and how-tos for using the OSPool and OSDF.\n",
    "* **Email support**: get help within 1-2 business days by emailing [support@osg-htc.org](mailto:support@osg-htc.org).\n",
    "* **Virtual office hours**: live discussions with facilitators - see the [Email, Office Hours, and 1-1 Meetings](https://portal.osg-htc.org/documentation/support_and_training/support/getting-help-from-RCFs/) page for current schedule.\n",
    "* **One-on-one meetings**: dedicated meetings to help new users, groups get started on the system; email [support@osg-htc.org](mailto:support@osg-htc.org) to request a meeting.\n",
    "\n",
    "This information, and more, is provided in our [Get Help](https://portal.osg-htc.org/documentation/support_and_training/support/getting-help-from-RCFs/) page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash (conda: base) *",
   "language": "bash",
   "name": "conda-base-bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
